#!/usr/bin/env python3
"""
ğŸš€ ENTRAÃNEMENT MINDSPORE - DEPUIS NEON
Utilise les VRAIES donnÃ©es de la base de donnÃ©es
Sauvegarde les fichiers dans backend/ai_models/

Auteur: Ã‰quipe Serre Intelligente
Date: 2026
Version: 2.0
"""

import os
import sys
import numpy as np
import pandas as pd
import json
import mindspore as ms
from mindspore import nn, Tensor, context, save_checkpoint
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib
from sqlalchemy import create_engine, text
from datetime import datetime
from dotenv import load_dotenv

# ============================================
# CONFIGURATION
# ============================================
# DÃ©terminer le chemin absolu du projet
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
BACKEND_DIR = os.path.join(PROJECT_ROOT, "backend")
AI_MODELS_DIR = os.path.join(BACKEND_DIR, "ai_models")
ENV_FILE = os.path.join(BACKEND_DIR, ".env")

print("=" * 70)
print("ğŸŒ¿ ENTRAÃNEMENT DU MODÃˆLE MINDSPORE - SERRE INTELLIGENTE")
print("=" * 70)
print(f"ğŸ“ Racine du projet: {PROJECT_ROOT}")
print(f"ğŸ“ Dossier de sauvegarde: {AI_MODELS_DIR}")
print(f"ğŸ“ Fichier .env: {ENV_FILE}")

# ============================================
# CONFIGURATION MINDSPORE
# ============================================
context.set_context(mode=context.GRAPH_MODE, device_target="CPU")
print(f"ğŸ§  MindSpore version: {ms.__version__}")

# ============================================
# 1. CHARGEMENT DES VARIABLES D'ENVIRONNEMENT
# ============================================
print("\nğŸ“‚ Chargement des variables d'environnement...")

if not os.path.exists(ENV_FILE):
    print(f"âŒ Fichier .env non trouvÃ©: {ENV_FILE}")
    print("   VÃ©rifie que backend/.env existe")
    sys.exit(1)

load_dotenv(ENV_FILE)
DATABASE_URL = os.getenv("DATABASE_URL")

if not DATABASE_URL:
    print("âŒ DATABASE_URL non trouvÃ©e dans .env")
    print("   VÃ©rifie le contenu de backend/.env")
    sys.exit(1)

print(f"âœ… DATABASE_URL chargÃ©e: {DATABASE_URL[:50]}...")

# ============================================
# 2. CONNEXION Ã€ NEON
# ============================================
print("\nğŸ“‚ Connexion Ã  Neon...")

try:
    engine = create_engine(DATABASE_URL)
    # Test de connexion
    with engine.connect() as conn:
        conn.execute(text("SELECT 1"))
    print("âœ… Connexion Ã  Neon rÃ©ussie")
except Exception as e:
    print(f"âŒ Erreur de connexion Ã  Neon: {e}")
    sys.exit(1)

# ============================================
# 3. CHARGEMENT DES DONNÃ‰ES
# ============================================
print("\nğŸ“Š Chargement des donnÃ©es depuis Neon...")

query = """
SELECT 
    temperature, 
    humidity, 
    light, 
    soil_moisture,
    timestamp
FROM sensor_readings 
WHERE timestamp > NOW() - INTERVAL '30 days'
ORDER BY timestamp
"""

try:
    df = pd.read_sql(query, engine)
    print(f"   âœ… {len(df)} mesures chargÃ©es")
except Exception as e:
    print(f"âŒ Erreur lors du chargement des donnÃ©es: {e}")
    sys.exit(1)

if len(df) < 100:
    print("   âš ï¸ Pas assez de donnÃ©es ! Minimum requis: 100 mesures")
    print(f"   Actuellement: {len(df)} mesures")
    print("   Laisse l'ESP32 ou le simulateur tourner plus longtemps.")
    sys.exit(1)

print(f"   âœ… PÃ©riode couverte: {df['timestamp'].min()} Ã  {df['timestamp'].max()}")

# ============================================
# 4. CRÃ‰ATION DES FEATURES
# ============================================
print("\nğŸ”§ CrÃ©ation des features...")

df = df.sort_values('timestamp')

# Features temporelles
df['hour'] = pd.to_datetime(df['timestamp']).dt.hour
df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)

# Lags (t-1, t-2, t-3, t-6)
for col in ['temperature', 'humidity', 'light', 'soil_moisture']:
    df[f'{col}_lag_1'] = df[col].shift(1)
    df[f'{col}_lag_2'] = df[col].shift(2)
    df[f'{col}_lag_3'] = df[col].shift(3)
    df[f'{col}_lag_6'] = df[col].shift(6)

# Moyennes mobiles
for col in ['temperature', 'humidity']:
    df[f'{col}_ma_3'] = df[col].rolling(3).mean()
    df[f'{col}_ma_6'] = df[col].rolling(6).mean()

# DiffÃ©rences
df['temp_diff'] = df['temperature'].diff()
df['hum_diff'] = df['humidity'].diff()

# Supprimer les NaN
df = df.dropna()
print(f"   âœ… {len(df)} Ã©chantillons aprÃ¨s crÃ©ation des features")

# ============================================
# 5. PRÃ‰PARATION X et y
# ============================================
target_cols = ['temperature', 'humidity', 'light', 'soil_moisture']
feature_cols = [col for col in df.columns if col not in target_cols + ['timestamp', 'hour']]

X = df[feature_cols].values.astype(np.float32)
y = df[target_cols].values.astype(np.float32)

print(f"   âœ… Features: {len(feature_cols)}")
print(f"   âœ… Targets: {len(target_cols)}")
print(f"   âœ… Forme X: {X.shape}")
print(f"   âœ… Forme y: {y.shape}")

# ============================================
# 6. NORMALISATION
# ============================================
print("\nğŸ“Š Normalisation des donnÃ©es...")

scaler_X = StandardScaler()
scaler_y = StandardScaler()

X_norm = scaler_X.fit_transform(X)
y_norm = scaler_y.fit_transform(y)

print(f"   âœ… X normalisÃ©: Î¼â‰ˆ0, Ïƒâ‰ˆ1")
print(f"   âœ… y normalisÃ©: Î¼â‰ˆ0, Ïƒâ‰ˆ1")

# ============================================
# 7. DÃ‰FINITION DU MODÃˆLE
# ============================================
print("\nğŸ§  CrÃ©ation du modÃ¨le MindSpore...")


class ClimatePredictor(nn.Cell):
    """
    RÃ©seau de neurones pour la prÃ©diction climatique
    Architecture: Dense + BatchNorm + ReLU + Dense + BatchNorm + ReLU + Dense
    """

    def __init__(self, input_dim, hidden_dim=64, output_dim=4):
        super().__init__()
        self.fc1 = nn.Dense(input_dim, hidden_dim)
        self.bn1 = nn.BatchNorm1d(hidden_dim)
        self.relu = nn.ReLU()
        self.fc2 = nn.Dense(hidden_dim, hidden_dim // 2)
        self.bn2 = nn.BatchNorm1d(hidden_dim // 2)
        self.fc3 = nn.Dense(hidden_dim // 2, output_dim)

    def construct(self, x):
        x = self.fc1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.fc3(x)
        return x


model = ClimatePredictor(input_dim=X.shape[1])
print(f"   âœ… Architecture: {X.shape[1]} â†’ 64 â†’ 32 â†’ 4")

# ============================================
# 8. ENTRAÃNEMENT
# ============================================
print("\nğŸš€ EntraÃ®nement MindSpore...")

loss_fn = nn.MSELoss()
optimizer = nn.Adam(model.trainable_params(), learning_rate=0.001)

X_tensor = Tensor(X_norm, ms.float32)
y_tensor = Tensor(y_norm, ms.float32)


def forward_fn(X, y):
    return loss_fn(model(X), y)


grad_fn = ms.value_and_grad(forward_fn, None, optimizer.parameters)

epochs = 50
losses = []

for epoch in range(epochs):
    loss, grads = grad_fn(X_tensor, y_tensor)
    optimizer(grads)
    loss_value = loss.asnumpy()
    losses.append(loss_value)

    if (epoch + 1) % 10 == 0:
        print(f"   Ã‰poque {epoch + 1:2d}/{epochs} - Loss: {loss_value:.6f}")

print(f"   âœ… EntraÃ®nement terminÃ©. Loss finale: {losses[-1]:.6f}")

# ============================================
# 9. Ã‰VALUATION
# ============================================
print("\nğŸ“Š Ã‰valuation du modÃ¨le...")

X_train, X_test, y_train, y_test = train_test_split(
    X_norm, y_norm, test_size=0.2, random_state=42
)

model.set_train(False)
X_test_tensor = Tensor(X_test, ms.float32)
y_pred_norm = model(X_test_tensor).asnumpy()

# DÃ©normalisation
y_test_real = scaler_y.inverse_transform(y_test)
y_pred_real = scaler_y.inverse_transform(y_pred_norm)

from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

mse = mean_squared_error(y_test_real, y_pred_real)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test_real, y_pred_real)
r2 = r2_score(y_test_real, y_pred_real)

print(f"   ğŸ“‰ MSE:  {mse:.4f}")
print(f"   ğŸ“Š RMSE: {rmse:.4f}")
print(f"   ğŸ“ MAE:  {mae:.4f}")
print(f"   ğŸ¯ RÂ²:   {r2:.4f}")

# DÃ©tail par target
print("\nğŸ“ˆ DÃ©tail par variable:")
target_names = ['ğŸŒ¡ï¸ TempÃ©rature', 'ğŸ’§ HumiditÃ©', 'ğŸ’¡ LumiÃ¨re', 'ğŸŒ± Sol']
for i, name in enumerate(target_names):
    mse_i = mean_squared_error(y_test_real[:, i], y_pred_real[:, i])
    print(f"   {name}: MSE={mse_i:.4f}")

# ============================================
# 10. SAUVEGARDE DES FICHIERS
# ============================================
print("\nğŸ’¾ Sauvegarde des fichiers...")

# CrÃ©er le dossier s'il n'existe pas
os.makedirs(AI_MODELS_DIR, exist_ok=True)
print(f"   âœ… Dossier vÃ©rifiÃ©: {AI_MODELS_DIR}")

# Sauvegarde du modÃ¨le MindSpore
model_path = os.path.join(AI_MODELS_DIR, "climate_model.ckpt")
save_checkpoint(model, model_path)
print(f"   âœ… ModÃ¨le: {model_path}")

# Sauvegarde des scalers
scaler_X_path = os.path.join(AI_MODELS_DIR, "scaler_X.pkl")
scaler_y_path = os.path.join(AI_MODELS_DIR, "scaler_y.pkl")
joblib.dump(scaler_X, scaler_X_path)
joblib.dump(scaler_y, scaler_y_path)
print(f"   âœ… Scalers: scaler_X.pkl, scaler_y.pkl")

# Sauvegarde des informations du modÃ¨le
model_info = {
    'feature_cols': feature_cols,
    'target_cols': target_cols,
    'input_dim': X.shape[1],
    'hidden_dim': 64,
    'output_dim': 4,
    'model_type': 'MindSpore',
    'samples': len(X),
    'mse': float(mse),
    'rmse': float(rmse),
    'mae': float(mae),
    'r2': float(r2),
    'training_date': datetime.now().isoformat(),
    'data_start': df['timestamp'].min().isoformat() if len(df) > 0 else None,
    'data_end': df['timestamp'].max().isoformat() if len(df) > 0 else None
}

info_path = os.path.join(AI_MODELS_DIR, "model_info.json")
with open(info_path, 'w', encoding='utf-8') as f:
    json.dump(model_info, f, indent=2, ensure_ascii=False)
print(f"   âœ… Configuration: {info_path}")

# ============================================
# 11. VÃ‰RIFICATION FINALE
# ============================================
print("\nğŸ” VÃ©rification des fichiers sauvegardÃ©s:")
files = os.listdir(AI_MODELS_DIR)
for f in files:
    size = os.path.getsize(os.path.join(AI_MODELS_DIR, f))
    print(f"   ğŸ“„ {f:25} ({size / 1024:.1f} Ko)")

# ============================================
# 12. TEST RAPIDE DE PRÃ‰DICTION
# ============================================
print("\nğŸ”® Test de prÃ©diction avec le modÃ¨le entraÃ®nÃ©...")

# Prendre un Ã©chantillon de test
sample = X[0:1]
sample_norm = scaler_X.transform(sample)
sample_tensor = Tensor(sample_norm, ms.float32)
pred_norm = model(sample_tensor).asnumpy()
pred = scaler_y.inverse_transform(pred_norm)

print(f"   ğŸŒ¡ï¸ TempÃ©rature prÃ©dite: {pred[0, 0]:.1f}Â°C")
print(f"   ğŸ’§ HumiditÃ© prÃ©dite: {pred[0, 1]:.1f}%")
print(f"   ğŸ’¡ LumiÃ¨re prÃ©dite: {pred[0, 2]:.0f} lux")
print(f"   ğŸŒ± Sol prÃ©dit: {pred[0, 3]:.1f}%")

# ============================================
# FIN
# ============================================
print("\n" + "=" * 70)
print("ğŸ‰ ENTRAÃNEMENT TERMINÃ‰ AVEC SUCCÃˆS !")
print("=" * 70)
print(f"\nğŸ“ ModÃ¨le prÃªt dans: {AI_MODELS_DIR}")
print("\nğŸš€ Tu peux maintenant :")
print("   1. Relancer l'API: uvicorn backend.api.main:app --reload")
print("   2. VÃ©rifier les prÃ©dictions: http://localhost:8000/api/v1/predictions/latest")
print("   3. DÃ©ployer sur Koyeb (git push)")
print("=" * 70)